{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code 4-67 to Code 4-81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the ner data saved in 5_NER_news_entity_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "t1 = pd.read_csv(\"only_ner_tagged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the data into 2 lists one with space and one without space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22762, 21726, 12239, 12239)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####start from here\n",
    "t2 = t1[t1.ner_words.str.len()>=4]\n",
    "t2[\"ner_words1\"] = t2[\"ner_words\"].str.lower()\n",
    "t2[\"ner_words2\"] = t2[\"ner_words1\"].str.replace(\" \",\"\")\n",
    "ner_list_space = t2[\"ner_words1\"].unique()\n",
    "ner_list = pd.Series(ner_list_space).str.replace(\" \",\"\")\n",
    "len(t1),len(t2),len(ner_list_space),len(ner_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files generated in \"6_Sparql_Wikidata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wiki_names = pd.read_csv(\"wikidata\\persons_india.csv\")\n",
    "wiki_places = pd.read_csv(\"wikidata\\city_state_country.csv\")\n",
    "wiki_positions = pd.read_csv(\"wikidata\\positions_india.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>itemLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q55713</td>\n",
       "      <td>Anand Yadav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q55716</td>\n",
       "      <td>Bhargavaram Viththal Varerkar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q55719</td>\n",
       "      <td>Sarojini Vaidya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wikidata.org/entity/Q55735</td>\n",
       "      <td>Aroon Tikekar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wikidata.org/entity/Q55744</td>\n",
       "      <td>Vijay Tendulkar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    item                      itemLabel\n",
       "0  http://www.wikidata.org/entity/Q55713                    Anand Yadav\n",
       "1  http://www.wikidata.org/entity/Q55716  Bhargavaram Viththal Varerkar\n",
       "2  http://www.wikidata.org/entity/Q55719                Sarojini Vaidya\n",
       "3  http://www.wikidata.org/entity/Q55735                  Aroon Tikekar\n",
       "4  http://www.wikidata.org/entity/Q55744                Vijay Tendulkar"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>cityLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1154</td>\n",
       "      <td>Jamnagar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q9461</td>\n",
       "      <td>Khedbrahma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q9894</td>\n",
       "      <td>Dharmapuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wikidata.org/entity/Q11854</td>\n",
       "      <td>Rajkot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wikidata.org/entity/Q13221</td>\n",
       "      <td>Tezu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    city   cityLabel\n",
       "0   http://www.wikidata.org/entity/Q1154    Jamnagar\n",
       "1   http://www.wikidata.org/entity/Q9461  Khedbrahma\n",
       "2   http://www.wikidata.org/entity/Q9894  Dharmapuri\n",
       "3  http://www.wikidata.org/entity/Q11854      Rajkot\n",
       "4  http://www.wikidata.org/entity/Q13221        Tezu"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##places in india and countries of word\n",
    "wiki_places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postion</th>\n",
       "      <th>positionLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Minister of Telangana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Minister of Nagaland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Minister of Odisha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Minister of Punjab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Minister of Bihar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postion                positionLabel\n",
       "0      NaN  Chief Minister of Telangana\n",
       "1      NaN   Chief Minister of Nagaland\n",
       "2      NaN     Chief Minister of Odisha\n",
       "3      NaN     Chief Minister of Punjab\n",
       "4      NaN      Chief Minister of Bihar"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##positions of public importance in india\n",
    "wiki_positions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the columns and combining the files into a single dataframe. We then create non duplicate lists with and without spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "wiki_names.columns = [\"url\",\"itemLabel\"]\n",
    "wiki_places.columns = [\"url\",\"itemLabel\"]\n",
    "wiki_positions.columns = [\"url\",\"itemLabel1\"]\n",
    "##removing words like \"of Gujarat\",\"of Delhi\" to arrive at better similarity\n",
    "wiki_positions[\"itemLabel\"] = wiki_positions[\"itemLabel1\"].str.replace('of [a-zA-Z\\s]+','') \n",
    "\n",
    "wiki_names = wiki_names.drop_duplicates([\"itemLabel\"])\n",
    "wiki_places = wiki_places.drop_duplicates([\"itemLabel\"])\n",
    "wiki_positions = wiki_positions.drop_duplicates([\"itemLabel\"])\n",
    "\n",
    "\n",
    "wiki_all = pd.concat([wiki_names,wiki_places,wiki_positions],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_all[\"itemLabel1\"] = wiki_all[\"itemLabel\"].str.lower()\n",
    "item_list_space = pd.Series(wiki_all[\"itemLabel1\"].unique())\n",
    "wiki_all[\"itemLabel2\"] = wiki_all[\"itemLabel1\"].str.replace(\" \",\"\")\n",
    "\n",
    "item_list = pd.Series(item_list_space).str.replace(\" \",\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now vectorize the lists -  ner_list and item_list as well as ner_list_space,item_list_space . The lists with space get vectorized using word vectorizer (ner_list,item_list). The lists without space gets vectorized as character vectorizer (ner_list_space,item_list_space). We then concatenate the outputs into 2 single arrays - one for our shortlisted “named entities” and other for the wikidata corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer = 'char',ngram_range = (4,6),min_df=0.0001)\n",
    "ner_vect_char = vectorizer.fit_transform(ner_list)\n",
    "wiki_vect_char = vectorizer.transform(item_list)\n",
    "\n",
    "vectorizer1 = TfidfVectorizer(analyzer = 'word',ngram_range = (1,1),min_df=0.0001)\n",
    "ner_vect_word = vectorizer1.fit_transform(ner_list_space)\n",
    "wiki_vect_word = vectorizer1.transform(item_list_space)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cosine similarity of ner_vect and wiki_vect using sparse matrix as these arrays are large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import  hstack\n",
    "\n",
    "ner_vect = hstack([ner_vect_char,ner_vect_word])\n",
    "wiki_vect = hstack([wiki_vect_char,wiki_vect_word]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55548, 3532), (55548, 3532))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_vect_word.shape,wiki_vect_word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_vec = cosine_similarity(ner_vect,wiki_vect,dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12239x55548 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10967669 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider it as a match if the cosine similarity is greater than 0.6. Since we have a sparse matrix, we convert that to a “coordinate” format (coo). “coo” formats store data in 3 arrays one for row, column and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_match_label</th>\n",
       "      <th>ner_match_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malaikaarora</td>\n",
       "      <td>malaikaarorakhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manishmanikpuri</td>\n",
       "      <td>drmanishmandal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kashmirsingh</td>\n",
       "      <td>kashmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rupsa,india</td>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bassi,india</td>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wiki_match_label   ner_match_label\n",
       "0     malaikaarora  malaikaarorakhan\n",
       "1  manishmanikpuri    drmanishmandal\n",
       "2     kashmirsingh           kashmir\n",
       "3      rupsa,india             india\n",
       "4      bassi,india             india"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (sim_vec >=.6)\n",
    "coo = condition.tocoo()\n",
    "\n",
    "df_matches = pd.DataFrame(columns = [\"wiki_match_label\",\"ner_match_label\"])\n",
    "wiki_match_label = [item_list[i] for i in coo.col]\n",
    "\n",
    "ner_match_label = [ner_list[i] for i in coo.row]\n",
    "\n",
    "df_matches[\"wiki_match_label\"] = wiki_match_label\n",
    "df_matches[\"ner_match_label\"] = ner_match_label\n",
    "\n",
    "df_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49455"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We match with the original dataset (t2) to and get the non-matched entities as our final filtered organization entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13149"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = pd.merge(t2,df_matches, left_on = \"ner_words2\", right_on = \"ner_match_label\", how = \"left\")\n",
    "len(t3[t3.ner_match_label.isna()==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get counts of \"ner_words1\" which are not in negative lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "supreme court                                      222\n",
       "congress                                           141\n",
       "air india                                           94\n",
       "world cup                                           86\n",
       "open sans                                           77\n",
       "aam aadmi party                                     56\n",
       "india today                                         54\n",
       "police                                              53\n",
       "bharatiya janata party                              52\n",
       "also                                                51\n",
       "party                                               50\n",
       "indian army                                         40\n",
       "army                                                32\n",
       "income tax                                          29\n",
       "samajwadi party                                     29\n",
       "us president donald trump                           29\n",
       "high court                                          27\n",
       "bombay high court                                   27\n",
       "rajya sabha                                         26\n",
       "april                                               26\n",
       "lok sabha                                           25\n",
       "university                                          25\n",
       "state bank                                          24\n",
       "president donald trump                              24\n",
       "the supreme court                                   23\n",
       "pakistani                                           23\n",
       "international cricket council                       23\n",
       "janata dal                                          22\n",
       "assembly                                            22\n",
       "pm modi                                             22\n",
       "                                                  ... \n",
       "aaj tak salaam                                       1\n",
       "trade analyst komal nahata                           1\n",
       "congress mla surjit dhiman                           1\n",
       "koli                                                 1\n",
       "sea harriers of                                      1\n",
       "daily telegraph                                      1\n",
       "mlas and                                             1\n",
       "4.28pm                                               1\n",
       "the mann ki baat updates                             1\n",
       "faculty association                                  1\n",
       "jolie                                                1\n",
       "women and mythology | were they better off           1\n",
       "nfl draft.a january                                  1\n",
       "said.apart                                           1\n",
       "the elephanta island                                 1\n",
       "bbc one                                              1\n",
       "walter e washington convention centre                1\n",
       "steel                                                1\n",
       "film producers association                           1\n",
       "ishapemyworld @                                      1\n",
       "central board of customs                             1\n",
       "assembly in                                          1\n",
       "chinas parliament                                    1\n",
       "consul r. d. joshi and vice consul harpal singh      1\n",
       "pil and the case a                                   1\n",
       "pti.the coa                                          1\n",
       "& root eng                                           1\n",
       "central pay commission                               1\n",
       "business council                                     1\n",
       "jordan 's olympic                                    1\n",
       "Name: ner_words1, Length: 8207, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.loc[t3.ner_match_label.isna()==True,\"ner_words1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3[t3.ner_match_label.isna()==True].to_csv(\"ner_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chks = t3.loc[t3.ner_match_label.isna()==True,\"ner_words1\"].value_counts()\n",
    "len(chks[chks>=10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a lot of organizations in this list. We need to filter the list for the final list of organizations\n",
    "\n",
    "Three options are there\n",
    "\n",
    "1. There are 115 unique words if we apply a filter of count>= 10. We could stop here and proceed with the rest of the analysis.\n",
    "2. We could also inspect the entire list manually (All 8K+ records) and select the final list of organizations. \n",
    "3. We can also look at the fact that \"orgnanizations\" would contain less of meanigful English words than the regular \"English\" Phrases. An example is the word \"US President\" Vs \"Aam Aadmi Party\". The former has more \"meaningful\" content than the later in English. This is elaborated in the following step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is a script that  identifies the percentage of english words in every row here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enchant (\"https://pypi.org/project/pyenchant/) is a library that identifies english from non-english words. Demo given here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyenchant\n",
    "#You can install pyenchant using \"pip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "word_checks = enchant.Dict(\"en_US\")\n",
    "print (word_checks.check(\"Hello\"))\n",
    "print (word_checks.check(\"Xyz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrt_words = pd.DataFrame(t3.loc[t3.ner_match_label.isna()==True,\"ner_words1\"].value_counts()).reset_index()\n",
    "shrt_words.columns = [\"words\",\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_checks = enchant.Dict(\"en_US\")\n",
    "def chk_eng(word):\n",
    "    tot_flag = 0\n",
    "    for i in word.split():\n",
    "        flag = word_checks.check(i)\n",
    "        if(flag==True):\n",
    "            tot_flag = tot_flag +1\n",
    "    \n",
    "    return tot_flag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrt_words[\"eng_ind\"] = shrt_words[\"words\"].apply(chk_eng)\n",
    "shrt_words[\"word_cnt\"] = (shrt_words[\"words\"].str.count(\" \"))+1\n",
    "shrt_words[\"percent\"] = shrt_words[\"eng_ind\"]/shrt_words[\"word_cnt\"]\n",
    "shrt_words.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percent here is the \"meaningful\" english word percentage in each phrase. I used this as a filter while manually skimming throught the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>eng_ind</th>\n",
       "      <th>word_cnt</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>congress</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air india</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world cup</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open sans</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aam aadmi party</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>india today</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>police</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bharatiya janata party</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>also</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>party</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>indian army</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>army</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>income tax</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>samajwadi party</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>us president donald trump</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>high court</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bombay high court</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rajya sabha</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>april</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lok sabha</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>university</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>state bank</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>president donald trump</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the supreme court</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pakistani</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>international cricket council</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>janata dal</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>assembly</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pm modi</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>aaj tak salaam</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8178</th>\n",
       "      <td>trade analyst komal nahata</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8179</th>\n",
       "      <td>congress mla surjit dhiman</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8180</th>\n",
       "      <td>koli</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8181</th>\n",
       "      <td>sea harriers of</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8182</th>\n",
       "      <td>daily telegraph</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>mlas and</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184</th>\n",
       "      <td>4.28pm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>the mann ki baat updates</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>faculty association</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8187</th>\n",
       "      <td>jolie</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8188</th>\n",
       "      <td>women and mythology | were they better off</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8189</th>\n",
       "      <td>nfl draft.a january</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8190</th>\n",
       "      <td>said.apart</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191</th>\n",
       "      <td>the elephanta island</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>bbc one</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>walter e washington convention centre</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>steel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8195</th>\n",
       "      <td>film producers association</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8196</th>\n",
       "      <td>ishapemyworld @</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>central board of customs</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8198</th>\n",
       "      <td>assembly in</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>chinas parliament</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>consul r. d. joshi and vice consul harpal singh</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>pil and the case a</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>pti.the coa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>&amp; root eng</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8204</th>\n",
       "      <td>central pay commission</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>business council</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>jordan 's olympic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8207 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                words  count  eng_ind  \\\n",
       "0                                       supreme court    222        2   \n",
       "1                                            congress    141        1   \n",
       "2                                           air india     94        1   \n",
       "3                                           world cup     86        2   \n",
       "4                                           open sans     77        2   \n",
       "5                                     aam aadmi party     56        1   \n",
       "6                                         india today     54        1   \n",
       "7                                              police     53        1   \n",
       "8                              bharatiya janata party     52        1   \n",
       "9                                                also     51        1   \n",
       "10                                              party     50        1   \n",
       "11                                        indian army     40        1   \n",
       "12                                               army     32        1   \n",
       "13                                         income tax     29        2   \n",
       "14                                    samajwadi party     29        1   \n",
       "15                          us president donald trump     29        3   \n",
       "16                                         high court     27        2   \n",
       "17                                  bombay high court     27        2   \n",
       "18                                        rajya sabha     26        0   \n",
       "19                                              april     26        0   \n",
       "20                                          lok sabha     25        0   \n",
       "21                                         university     25        1   \n",
       "22                                         state bank     24        2   \n",
       "23                             president donald trump     24        2   \n",
       "24                                  the supreme court     23        3   \n",
       "25                                          pakistani     23        0   \n",
       "26                      international cricket council     23        3   \n",
       "27                                         janata dal     22        0   \n",
       "28                                           assembly     22        1   \n",
       "29                                            pm modi     22        1   \n",
       "...                                               ...    ...      ...   \n",
       "8177                                   aaj tak salaam      1        1   \n",
       "8178                       trade analyst komal nahata      1        2   \n",
       "8179                       congress mla surjit dhiman      1        1   \n",
       "8180                                             koli      1        0   \n",
       "8181                                  sea harriers of      1        3   \n",
       "8182                                  daily telegraph      1        2   \n",
       "8183                                         mlas and      1        1   \n",
       "8184                                           4.28pm      1        0   \n",
       "8185                         the mann ki baat updates      1        3   \n",
       "8186                              faculty association      1        2   \n",
       "8187                                            jolie      1        0   \n",
       "8188       women and mythology | were they better off      1        7   \n",
       "8189                              nfl draft.a january      1        0   \n",
       "8190                                       said.apart      1        0   \n",
       "8191                             the elephanta island      1        2   \n",
       "8192                                          bbc one      1        1   \n",
       "8193            walter e washington convention centre      1        2   \n",
       "8194                                            steel      1        1   \n",
       "8195                       film producers association      1        3   \n",
       "8196                                  ishapemyworld @      1        0   \n",
       "8197                         central board of customs      1        4   \n",
       "8198                                      assembly in      1        2   \n",
       "8199                                chinas parliament      1        1   \n",
       "8200  consul r. d. joshi and vice consul harpal singh      1        6   \n",
       "8201                               pil and the case a      1        4   \n",
       "8202                                      pti.the coa      1        0   \n",
       "8203                                       & root eng      1        2   \n",
       "8204                           central pay commission      1        3   \n",
       "8205                                 business council      1        2   \n",
       "8206                                jordan 's olympic      1        0   \n",
       "\n",
       "      word_cnt   percent  \n",
       "0            2  1.000000  \n",
       "1            1  1.000000  \n",
       "2            2  0.500000  \n",
       "3            2  1.000000  \n",
       "4            2  1.000000  \n",
       "5            3  0.333333  \n",
       "6            2  0.500000  \n",
       "7            1  1.000000  \n",
       "8            3  0.333333  \n",
       "9            1  1.000000  \n",
       "10           1  1.000000  \n",
       "11           2  0.500000  \n",
       "12           1  1.000000  \n",
       "13           2  1.000000  \n",
       "14           2  0.500000  \n",
       "15           4  0.750000  \n",
       "16           2  1.000000  \n",
       "17           3  0.666667  \n",
       "18           2  0.000000  \n",
       "19           1  0.000000  \n",
       "20           2  0.000000  \n",
       "21           1  1.000000  \n",
       "22           2  1.000000  \n",
       "23           3  0.666667  \n",
       "24           3  1.000000  \n",
       "25           1  0.000000  \n",
       "26           3  1.000000  \n",
       "27           2  0.000000  \n",
       "28           1  1.000000  \n",
       "29           2  0.500000  \n",
       "...        ...       ...  \n",
       "8177         3  0.333333  \n",
       "8178         4  0.500000  \n",
       "8179         4  0.250000  \n",
       "8180         1  0.000000  \n",
       "8181         3  1.000000  \n",
       "8182         2  1.000000  \n",
       "8183         2  0.500000  \n",
       "8184         1  0.000000  \n",
       "8185         5  0.600000  \n",
       "8186         2  1.000000  \n",
       "8187         1  0.000000  \n",
       "8188         8  0.875000  \n",
       "8189         3  0.000000  \n",
       "8190         1  0.000000  \n",
       "8191         3  0.666667  \n",
       "8192         2  0.500000  \n",
       "8193         5  0.400000  \n",
       "8194         1  1.000000  \n",
       "8195         3  1.000000  \n",
       "8196         2  0.000000  \n",
       "8197         4  1.000000  \n",
       "8198         2  1.000000  \n",
       "8199         2  0.500000  \n",
       "8200         9  0.666667  \n",
       "8201         5  0.800000  \n",
       "8202         2  0.000000  \n",
       "8203         3  0.666667  \n",
       "8204         3  1.000000  \n",
       "8205         2  1.000000  \n",
       "8206         3  0.000000  \n",
       "\n",
       "[8207 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrt_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually skimmed through this file of 8K records and arrived at the following words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- air india\n",
    "- gandhi institute of medical\n",
    "- red bull\n",
    "- united airlines\n",
    "- qatar airways\n",
    "- patanjali research institute\n",
    "- jet airways\n",
    "- millennium school\n",
    "- facebook\n",
    "- microsoft\n",
    "- cbfc\n",
    "- maruti celerio\n",
    "- facebook india md\n",
    "- sony xperia xz premium\n",
    "- foxx\n",
    "- uber ceo travis kalanick\n",
    "- bharti airtel\n",
    "- airtel\n",
    "- change.org\n",
    "- uber india president amit jain\n",
    "- emami\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda2-py36]",
   "language": "python",
   "name": "conda-env-Anaconda2-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
